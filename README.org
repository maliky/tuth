#+TITLE: Tusis program

* Tusis Application — Quickstart Guide

** Tusis Application Overview

Tusis is a student information and academic management system designed to streamline administrative tasks at the university. It manages student profiles, curricula, courses, registrations, class schedules, financial transactions, and role-based permissions, all through Django's admin interface.

This document summarizes how to run and test the Tusis application in different environments.
** Getting the Code
Clone the repository and enter its directory:
#+BEGIN_SRC bash
git clone <repository-url>
cd tusis
#+END_SRC
** The apps
Here are the different applications you will find in this directory:
| App Name | Description |
|------------+-----------------------------------------------------------|
| Registry | Handles student documents, registrations, and class rosters |
| Spaces | Manages buildings, rooms, and locations |
| Academics | Maintains courses, curricula, colleges, and prerequisites |
| Timetable | Schedules sections, semesters, academic years, and sessions |
| People | Manages user profiles, roles, and permissions |
| Finance | Processes payments, financial records, and scholarships |

** Running Locally without Docker
For a quick local setup using SQLite, run:
#+BEGIN_SRC bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp env-test .env
./run.sh -m  # check run.sh -h for documentation or look the source
#+END_SRC
Open http://127.0.0.1:8000 in your browser.


** Development Environment
To make changes :
The repo includes a ~.python-version~ file which instructs *pyenv* to use a
virtual environment named ~tusis~. You can create it with:
#+BEGIN_SRC bash
pyenv virtualenv 3.12.0 tusis
pyenv local tusis
#+END_SRC
If you prefer not to use ~pyenv virtualenv~, replace the file content with a
supported Python version such as ~3.12~.
- Create a new branch from `dev` or switch to the `dev` branch
- Make your changes
If you add Python libraries using `pip install ...`,
 - add them to `requirements-dev.txt`
#+BEGIN_SRC bash  
echo "xyz" > requirements-dev.txt
#+END_SRC
- Run code checks: 
#+BEGIN_SRC python
black app/ && flake8 app/ && mypy app/
#+END_SRC
*** Tests
Install dependencies from `requirements-dev.txt` and `requirements-test.txt` before running tests.
You can run `./run.sh -m` to start a fresh test on the local machine.

You can copy the reusable template stored at `Seed_data/db_seed_example.txt` or  populate your DB with a file having this structure:
#+BEGIN_SRC
academic_year: 25-26
semester: 1
college: CAFS
course_code: AGR
course_no: 121
course_long_code: AGR121-CAFS
course_title: Practicum I
credit_hours: 1
curriculum: Bsc Agriculture
section: 1
location: SAPEC-SAPEC
space: SAPEC
room: SAPEC
faculty: Prof A
weekday: Friday
start_time: 9:00
end_time: 10:00
#+END_VERBATIM

Check the `run.sh` script to see where to put the file.

Before starting the stack, copy the sample environment file:
#+BEGIN_SRC bash
cp .env-dev.example .env-dev
#+END_SRC

*** Launch your docker-compose dev environment
Build and start the dev stack:
#+BEGIN_SRC bash
docker-compose -f docker-compose-dev.yml up --build
#+END_SRC
Once the containers are running, visit [[https://localhost][https://localhost]] to access the app.

*** Running Tests
**** Using Docker

Run tests within the dev container:

#+BEGIN_SRC bash
docker-compose -f docker-compose-dev.yml run --rm web pytest tests/
#+END_SRC

Access the application at [[https://localhost][https://localhost]]

**** Without Docker (Linux)

Load the environment variables from your local `.env` file, then run pytest:

#+BEGIN_SRC bash
export $(grep -v '^#' .env | xargs)  # load variables
pytest tests/
#+END_SRC

**** Browser UI smoke tests
The Selenium suite exercises the public landing page and any future UI flows that require a real browser. Install the dev requirements, then run:
#+BEGIN_SRC bash
pytest -m selenium tests/selenium
#+END_SRC
By default the tests spin up a headless Chrome instance via =webdriver-manager=. You can tweak the driver with environment variables:
- ~SELENIUM_BROWSER~: `chrome` (default) or `firefox`
- ~SELENIUM_HEADLESS~: set to `0` to watch the browser
- ~SELENIUM_IMPLICIT_WAIT~: seconds to wait for DOM queries
example:
#+BEGIN_SRC bash
docker run -d --rm -p 4444:4444 -p 7900:7900 selenium/standalone-chrome:126.0
SELENIUM_REMOTE_URL=http://127.0.0.1:4444/wd/hub pytest -m selenium tests/selenium
#+END_SRC
When the variable is set the suite connects to the remote browser instead of starting a local one.
If the runtime disallows opening localhost sockets (some secure sandboxes do), the tests will be auto-skipped with a clear reason.

*** Restart from a clean state
#+BEGIN_SRC bash term2
  docker-compose -f docker-compose-dev.yml down -v
  sudo rm app/migrations/*
#+END_SRC

In another terminal,
#+BEGIN_SRC bash term2
   docker-compose -f docker-compose-dev.yml up --build
#+END_SRC

#+BEGIN_SRC bash  term3
    docker-compose -f docker-compose-dev.yml exec web python manage.py makemigrations app
    docker-compose -f docker-compose-dev.yml exec web python manage.py migrate
    docker-compose -f docker-compose-dev.yml exec web python manage.py populate_initial_data
#+END_SRC

*** Passwords
** Production Environment

Build and launch the production environment:

# Copy the sample production environment settings:
#+BEGIN_SRC bash
cp .env-prod.example .env-prod
#+END_SRC

#+begin_src bash
docker-compose -f docker-compose-prod.yml up --build -d
#+end_src

- Ensure that your production `.env-prod` file is configured and secure.

Access the application via your production URL (e.g., [[https://tuth.koba.sarl][https://tusis.koba.sarl]]).

** Pre-production Deployment (Docker + native Nginx)
This tier runs PostgreSQL and Django/Gunicorn in Docker, while the host’s native Nginx (already secured with your =htpasswd= in =/etc/nginx=) serves static/media files and proxies to the containerised app.

1. **Prepare secrets**
   - Copy the sample env file: ~cp .env-preprod.example .env-preprod~ and provide a secure secret key, hostnames, DB credentials, and Gunicorn sizing (port/workers/timeouts). Keep this file out of git.
2. **Build the stack**
   - Launch Postgres + the app: ~docker-compose -f docker-compose-preprod.yml up -d --build~.
   - The =deploy/preprod/entrypoint.sh= script blocks until Postgres is reachable, runs migrations, calls =collectstatic= (writing to the repo’s ~static/~ path), and starts Gunicorn bound to ~0.0.0.0:${GUNICORN_PORT:-8000}~. The compose file publishes that container port as ~127.0.0.1:18000~ on the host, so only the local Nginx can reach it.
   - Inspect status/logs with ~docker-compose -f docker-compose-preprod.yml ps~ and ~docker-compose -f docker-compose-preprod.yml logs -f web db~.
3. **Wire native Nginx**
   - Copy =infra/nginx/tusis.koba.sarl.conf= into =/etc/nginx/sites-available/=, tweak the TLS certificate paths (Let’s Encrypt shown as an example), and update the =auth_basic_user_file= path if your ~htpasswd~ lives somewhere else.
   - Symlink it into =sites-enabled/= (~sudo ln -s /etc/nginx/sites-available/tusis.koba.sarl.conf /etc/nginx/sites-enabled/~), then reload nginx (~sudo systemctl reload nginx~).
   - The config aliases static/media to =~/Tusis/Tusis_app/static= and =media=, so each deploy should include ~python manage.py collectstatic --noinput~ which the entrypoint already runs.
4. **Smoke-test**
   - Hit the local health check through Nginx: ~curl -u <user>:<pass> https://tusis.koba.sarl/healthz~ (expect =ok=). Without creds you should receive a 401 challenge from Basic Auth.
5. **Operate & back up**
   - Run management commands via ~docker-compose -f docker-compose-preprod.yml exec web python manage.py <command>~ (e.g., ~createsuperuser~, ~populate_initial_data~).
   - Capture database dumps from the db service: ~docker-compose -f docker-compose-preprod.yml exec db pg_dump -U $POSTGRES_USER $POSTGRES_DB > tusis-preprod-$(date +%F).sql~.
   - Deploy updates by pulling latest git changes, reviewing the env file, and rerunning ~docker-compose -f docker-compose-preprod.yml up -d --build~; migrations/statics are re-applied automatically by the entrypoint.

With this split, Nginx keeps handling TLS and Basic Auth on the host while the Python/PostgreSQL workloads stay reproducible inside Docker.

** Data Import/Export

Several admin screens expose Import and Export buttons powered by
the =django-import-export= package. Use these buttons to upload CSV
or XLSX files and to download existing records. Models such as
Courses, Curricula and Sections already provide corresponding
resources.


** Importing a full workbook
Use ``import_workbook`` to load an Excel file containing
``timetable``, ``academics``, ``people`` and ``spaces`` sheets.

# +begin_src bash
python manage.py import_workbook myfile.xlsx --dry-run
# +end_src
Run the command without ``--dry-run`` to persist changes.

* COMMENT
Installing nodes
Installing pyenv
Installing python 3.13
#+BEGIN_SRC bash  -i
pyenv install 3.13
pyenv virtualenv 3.13 tusis
pyenv local tusis
#+END_SRC
Installing librairies
** special lib

*** pygraphviz
#+BEGIN_SRC bash  -i
sudo apt-get install graphviz graphviz-dev
pip install pygraphviz
#+END_SRC

pip install -r requirements-dev

Installing webdriver
Installing DB posgresql
Installing IDE / codex
